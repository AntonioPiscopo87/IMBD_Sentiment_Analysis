{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Let's do some basics import and CountVectorizer so to call the transform() function on one or more documents as needed to encode each as a vector\n",
    "from os import path\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import some NLP modules such as PorterStemmer, SnowballStemmer, WordNetLemmetizer\n",
    "# download vader_lexicon, and stopwords\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer    # Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some visualization modules\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud   # Sentiment-based Word Clouds\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change and set directory to kaggle/input\n",
    "\n",
    "os.chdir('/kaggle/input')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       object\n",
       "sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read IMDB Dataset and store it into a dataframe \"df\"\n",
    "\n",
    "df=pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv',header=0,error_bad_lines=True,encoding='utf8')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at our table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function \"sc\" to run sentimental analysis on the text \"review\" and return the compound value (-1 to +1)\n",
    "def sc(x):\n",
    "    score=SentimentIntensityAnalyzer().polarity_scores(x)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's apply the compound score of our sentimental analysis to \"review\" storing the results in a new column \"SentScore\" through \n",
    "# map function\n",
    "\n",
    "df[\"SentScore\"]=df[\"review\"].map(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>SentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.9951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  SentScore\n",
       "0  One of the other reviewers has mentioned that ...  positive    -0.9951\n",
       "1  A wonderful little production. <br /><br />The...  positive     0.9641\n",
       "2  I thought this was a wonderful way to spend ti...  positive     0.9605\n",
       "3  Basically there's a family where a little boy ...  negative    -0.9213\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at our updated table \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function \"sc\" to run sentimental analysis on the text \"review\" and return the compound value (-1 to +1)\n",
    "\n",
    "\n",
    "def sca(lb):\n",
    "    if lb >= .6:\n",
    "        return \"Very Good\"\n",
    "    elif (lb > .2) and (lb < .6):\n",
    "        return \"Good\"\n",
    "    elif (lb > -.2) and (lb < .2):\n",
    "        return \"Average\"\n",
    "    elif (lb > -.6) and (lb < -.2):\n",
    "        return \"Disappointing\"\n",
    "     \n",
    "    else:\n",
    "        return \"Regrettable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we insert a column to indicate the class of the review (\"Very Good\" , \"Good\", \"Average\", \"Disappointing\", \"Regrettable\")\n",
    "\n",
    "df[\"SentClass\"]=df[\"SentScore\"].map(sca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>SentScore</th>\n",
       "      <th>SentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.9951</td>\n",
       "      <td>Regrettable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>Regrettable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.5223</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9721</td>\n",
       "      <td>Regrettable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment  SentScore  \\\n",
       "0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n",
       "1   A wonderful little production. <br /><br />The...  positive     0.9641   \n",
       "2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n",
       "3   Basically there's a family where a little boy ...  negative    -0.9213   \n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n",
       "5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n",
       "6   I sure would like to see a resurrection of a u...  positive     0.9022   \n",
       "7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n",
       "8   Encouraged by the positive comments about this...  negative     0.2362   \n",
       "9   If you like original gut wrenching laughter yo...  positive     0.9149   \n",
       "10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n",
       "11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n",
       "12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n",
       "14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n",
       "\n",
       "      SentClass  \n",
       "0   Regrettable  \n",
       "1     Very Good  \n",
       "2     Very Good  \n",
       "3   Regrettable  \n",
       "4     Very Good  \n",
       "5     Very Good  \n",
       "6     Very Good  \n",
       "7     Very Good  \n",
       "8          Good  \n",
       "9     Very Good  \n",
       "10    Very Good  \n",
       "11         Good  \n",
       "12  Regrettable  \n",
       "13         Good  \n",
       "14    Very Good  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check our updated table\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function for which relatively to the \"sentiment\" column, positive=1 | negative=0\n",
    "\n",
    "def num(lb):\n",
    "    if lb == 'positive':\n",
    "        return 1   \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column \"sentiment_bin\" applying the function above using .map\n",
    "\n",
    "df[\"sentiment_bin\"]=df[\"sentiment\"].map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>SentScore</th>\n",
       "      <th>SentClass</th>\n",
       "      <th>sentiment_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.9951</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.5223</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9721</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment  SentScore  \\\n",
       "0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n",
       "1   A wonderful little production. <br /><br />The...  positive     0.9641   \n",
       "2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n",
       "3   Basically there's a family where a little boy ...  negative    -0.9213   \n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n",
       "5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n",
       "6   I sure would like to see a resurrection of a u...  positive     0.9022   \n",
       "7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n",
       "8   Encouraged by the positive comments about this...  negative     0.2362   \n",
       "9   If you like original gut wrenching laughter yo...  positive     0.9149   \n",
       "10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n",
       "11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n",
       "12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n",
       "14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n",
       "\n",
       "      SentClass  sentiment_bin  \n",
       "0   Regrettable              1  \n",
       "1     Very Good              1  \n",
       "2     Very Good              1  \n",
       "3   Regrettable              0  \n",
       "4     Very Good              1  \n",
       "5     Very Good              1  \n",
       "6     Very Good              1  \n",
       "7     Very Good              0  \n",
       "8          Good              0  \n",
       "9     Very Good              1  \n",
       "10    Very Good              0  \n",
       "11         Good              0  \n",
       "12  Regrettable              0  \n",
       "13         Good              0  \n",
       "14    Very Good              1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the updated table\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly to what we did above, for the SentScore results (-1 to +1) we define a function for which a value >= 0 equals 1(positive), else 0(negative)\n",
    "\n",
    "def numscore(lb):\n",
    "    if lb >= 0:\n",
    "        return 1     \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column \"SentScore_bin\" applying the function above using .map\n",
    "\n",
    "df[\"SentScore_bin\"]=df[\"SentScore\"].map(numscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>SentScore</th>\n",
       "      <th>SentClass</th>\n",
       "      <th>sentiment_bin</th>\n",
       "      <th>SentScore_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.9951</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.5223</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9721</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment  SentScore  \\\n",
       "0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n",
       "1   A wonderful little production. <br /><br />The...  positive     0.9641   \n",
       "2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n",
       "3   Basically there's a family where a little boy ...  negative    -0.9213   \n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n",
       "5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n",
       "6   I sure would like to see a resurrection of a u...  positive     0.9022   \n",
       "7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n",
       "8   Encouraged by the positive comments about this...  negative     0.2362   \n",
       "9   If you like original gut wrenching laughter yo...  positive     0.9149   \n",
       "10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n",
       "11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n",
       "12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n",
       "14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n",
       "\n",
       "      SentClass  sentiment_bin  SentScore_bin  \n",
       "0   Regrettable              1              0  \n",
       "1     Very Good              1              1  \n",
       "2     Very Good              1              1  \n",
       "3   Regrettable              0              0  \n",
       "4     Very Good              1              1  \n",
       "5     Very Good              1              1  \n",
       "6     Very Good              1              1  \n",
       "7     Very Good              0              1  \n",
       "8          Good              0              1  \n",
       "9     Very Good              1              1  \n",
       "10    Very Good              0              1  \n",
       "11         Good              0              1  \n",
       "12  Regrettable              0              0  \n",
       "13         Good              0              1  \n",
       "14    Very Good              1              1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the updated table\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do now some TEXT ADJUSTMENTS / CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make text lower case\n",
    "df[\"review\"]  = df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove digits from text\n",
    "def Remove_digit(text):\n",
    "    result = re.sub(r\"\\d\", \"\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML from text\n",
    "def remove_html(text):\n",
    "    result = re.sub(r'<.*?>','',text) # Find out anything that is in between < & > symbol \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special text characters\n",
    "def remove_spl(text):\n",
    "    result = re.sub(r'\\W',' ',text) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link words with similar meaning to one word (in context)\n",
    "def lem_word(text):\n",
    "    result= WordNetLemmatizer().lemmatize(text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply all of the above functions to the text column \"review\"\n",
    "\n",
    "df[\"review\"]  = df[\"review\"].apply(Remove_digit)\n",
    "df[\"review\"]  = df[\"review\"].apply(remove_html)\n",
    "df[\"review\"]  = df[\"review\"].apply(remove_spl)\n",
    "df[\"review\"]  = df[\"review\"].apply(lem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>SentScore</th>\n",
       "      <th>SentClass</th>\n",
       "      <th>sentiment_bin</th>\n",
       "      <th>SentScore_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.9951</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production  the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>Regrettable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s  love in the time of money  is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  SentScore  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive    -0.9951   \n",
       "1  a wonderful little production  the filming tec...  positive     0.9641   \n",
       "2  i thought this was a wonderful way to spend ti...  positive     0.9605   \n",
       "3  basically there s a family where a little boy ...  negative    -0.9213   \n",
       "4  petter mattei s  love in the time of money  is...  positive     0.9744   \n",
       "\n",
       "     SentClass  sentiment_bin  SentScore_bin  \n",
       "0  Regrettable              1              0  \n",
       "1    Very Good              1              1  \n",
       "2    Very Good              1              1  \n",
       "3  Regrettable              0              0  \n",
       "4    Very Good              1              1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the updated table\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's store the adjusted text to the object 'corpus1' and transform it into a List\n",
    "corpus1=df['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an object \"corpus\" that includes the first 1000 values of the list 'corpus1', otherwise the machine could take too long to run the command\n",
    "\n",
    "corpus=corpus1[ :1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorisation\n",
    "# I have defined ngram range to be unigrams and bigrams (it starts with one word and goes up to two when vectorizing)\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "cv = text.CountVectorizer(input=corpus,ngram_range=(1,2),stop_words='english')\n",
    "matrix = cv.fit_transform(corpus)\n",
    "\n",
    "# I am converting the matrix_cv into a dataframe \n",
    "corpus2 = pd.DataFrame(matrix.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_fargo_</th>\n",
       "      <th>_fargo_ just</th>\n",
       "      <th>_inspire_</th>\n",
       "      <th>_inspire_ audience</th>\n",
       "      <th>aaargh</th>\n",
       "      <th>aaargh wes</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaliyah soul</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aamir khan</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulu simply</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick shame</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz imdb</th>\n",
       "      <th>élan</th>\n",
       "      <th>élan unique</th>\n",
       "      <th>ísnt</th>\n",
       "      <th>ísnt entertaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _fargo_  _fargo_ just  _inspire_  _inspire_ audience  aaargh  aaargh wes  \\\n",
       "0        0             0          0                   0       0           0   \n",
       "1        0             0          0                   0       0           0   \n",
       "2        0             0          0                   0       0           0   \n",
       "3        0             0          0                   0       0           0   \n",
       "4        0             0          0                   0       0           0   \n",
       "\n",
       "   aaliyah  aaliyah soul  aamir  aamir khan  ...  zulu  zulu simply  zwick  \\\n",
       "0        0             0      0           0  ...     0            0      0   \n",
       "1        0             0      0           0  ...     0            0      0   \n",
       "2        0             0      0           0  ...     0            0      0   \n",
       "3        0             0      0           0  ...     0            0      0   \n",
       "4        0             0      0           0  ...     0            0      0   \n",
       "\n",
       "   zwick shame  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz imdb  élan  \\\n",
       "0            0                   0                        0     0   \n",
       "1            0                   0                        0     0   \n",
       "2            0                   0                        0     0   \n",
       "3            0                   0                        0     0   \n",
       "4            0                   0                        0     0   \n",
       "\n",
       "   élan unique  ísnt  ísnt entertaining  \n",
       "0            0     0                  0  \n",
       "1            0     0                  0  \n",
       "2            0     0                  0  \n",
       "3            0     0                  0  \n",
       "4            0     0                  0  \n",
       "\n",
       "[5 rows x 110012 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a snapshot at the data\n",
    "corpus2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 110012)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One thing to notice here is the dimension of this data\n",
    "# We have 1000 documents (rows) which is consistent with the selected amount of rows of our list corpus \n",
    "# and 110012 columns which is humangous. We have a created a giant matrix\n",
    "\n",
    "# It is noticeable that many features contain 0, since not all words willbe present across documents of the corpus(2)\n",
    "\n",
    "corpus2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF, Term Frequency and Inverse Document Freq\n",
    "# We run a TF-IDF representation on the same corpus, same like before and also this time removing the english stop_words\n",
    "\n",
    "\n",
    "tf = text.TfidfVectorizer(input=corpus, ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "matrix1 = tf.fit_transform(corpus)\n",
    "\n",
    "# I am converting the matrix1 into a dataframe X\n",
    "X = pd.DataFrame(matrix1.toarray(), columns=tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_fargo_</th>\n",
       "      <th>_fargo_ just</th>\n",
       "      <th>_inspire_</th>\n",
       "      <th>_inspire_ audience</th>\n",
       "      <th>aaargh</th>\n",
       "      <th>aaargh wes</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaliyah soul</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aamir khan</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulu simply</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwick shame</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz imdb</th>\n",
       "      <th>élan</th>\n",
       "      <th>élan unique</th>\n",
       "      <th>ísnt</th>\n",
       "      <th>ísnt entertaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _fargo_  _fargo_ just  _inspire_  _inspire_ audience  aaargh  aaargh wes  \\\n",
       "0      0.0           0.0        0.0                 0.0     0.0         0.0   \n",
       "1      0.0           0.0        0.0                 0.0     0.0         0.0   \n",
       "2      0.0           0.0        0.0                 0.0     0.0         0.0   \n",
       "3      0.0           0.0        0.0                 0.0     0.0         0.0   \n",
       "4      0.0           0.0        0.0                 0.0     0.0         0.0   \n",
       "\n",
       "   aaliyah  aaliyah soul  aamir  aamir khan  ...  zulu  zulu simply  zwick  \\\n",
       "0      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n",
       "1      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n",
       "2      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n",
       "3      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n",
       "4      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n",
       "\n",
       "   zwick shame  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz imdb  élan  \\\n",
       "0          0.0                 0.0                      0.0   0.0   \n",
       "1          0.0                 0.0                      0.0   0.0   \n",
       "2          0.0                 0.0                      0.0   0.0   \n",
       "3          0.0                 0.0                      0.0   0.0   \n",
       "4          0.0                 0.0                      0.0   0.0   \n",
       "\n",
       "   élan unique  ísnt  ísnt entertaining  \n",
       "0          0.0   0.0                0.0  \n",
       "1          0.0   0.0                0.0  \n",
       "2          0.0   0.0                0.0  \n",
       "3          0.0   0.0                0.0  \n",
       "4          0.0   0.0                0.0  \n",
       "\n",
       "[5 rows x 110012 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at our matrix X\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set our y to be the first 1000 values of the column SentScore_bin (based on our sentiment analysis)\n",
    "\n",
    "y = df['SentScore_bin'][:1000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1\n",
      " 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
      " 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1\n",
      " 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0\n",
      " 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0\n",
      " 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the array 'y'\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to try and run the RandomForest Classifier on X= vectorized matrix and y= SentScore_bin\n",
    "# using the fit transformation of the tf - idf matrix to array =X\n",
    "\n",
    "# Let's split X and y in training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=0.3,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=9,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set the RandomForestClassifier and set the parameters\n",
    "# Let's fit the model on X and y training data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier=RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=4, min_samples_split=9, n_estimators=100)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the prediction on the X test data and store them into the object 'predictions'\n",
    "\n",
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32  45]\n",
      " [ 19 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.42      0.50        77\n",
      "           1       0.70      0.85      0.76       123\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.66      0.63      0.63       200\n",
      "weighted avg       0.67      0.68      0.66       200\n",
      "\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "# We can see that running the RANDOM FOREST CLASSIFIER we get an accuracy score of 68%. NOT amazing!\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    " \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=23, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "lr=LogisticRegression(C=1.0,class_weight=None,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=100,\n",
    "multi_class='auto',n_jobs=None,penalty='l2',random_state=23,solver='lbfgs',tol=0.0001,verbose=0,warm_start=False)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(X_train,y_train)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(X_test)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.615\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score running a LOGISTIC REGRESSION is pretty low.....only 61.5%!\n",
    "\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(y_test,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        77\n",
      "           1       0.61      1.00      0.76       123\n",
      "\n",
      "    accuracy                           0.61       200\n",
      "   macro avg       0.31      0.50      0.38       200\n",
      "weighted avg       0.38      0.61      0.47       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(y_test,lr_tfidf_predict,target_names=['0','1'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=80,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "mod=GridSearchCV(clf,param_grid={'n_estimators': [80,100,120,140,160]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=80,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=23,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None, param_grid={'n_estimators': [80]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=100,random_state=23)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6343      0.067244\n",
       "41101     0.061226\n",
       "108616    0.056553\n",
       "8108      0.043326\n",
       "65082     0.035758\n",
       "            ...   \n",
       "73273     0.000000\n",
       "73274     0.000000\n",
       "73275     0.000000\n",
       "73276     0.000000\n",
       "0         0.000000\n",
       "Length: 110012, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp=pd.Series(clf.feature_importances_)\n",
    "feature_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now repeat the operations setting the first 1000 values of our column 'sentiment_bin' as our \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment_bin'][:1000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split again in training and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=0.3,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=9,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier=RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=4, min_samples_split=9, n_estimators=100)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 27]\n",
      " [18 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       103\n",
      "           1       0.75      0.81      0.78        97\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.78      0.77       200\n",
      "weighted avg       0.78      0.78      0.77       200\n",
      "\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "# It seems to be more accurate with a score of 78%!\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    " \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=23, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Let's try again LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#training the model\n",
    "lr=LogisticRegression(C=1.0,class_weight=None,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=100,\n",
    "multi_class='auto',n_jobs=None,penalty='l2',random_state=23,solver='lbfgs',tol=0.0001,verbose=0,warm_start=False)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(X_train,y_train)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(X_test)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.805\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with y=sentiment_bin gives us the highest accuracy----81%! Not bad\n",
    "\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(y_test,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79       103\n",
      "           1       0.75      0.89      0.82        97\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.80       200\n",
      "weighted avg       0.82      0.81      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(y_test,lr_tfidf_predict,target_names=['0','1'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try with the GRADIENT BOOSTING CLASSIFIER\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf=GradientBoostingClassifier(n_estimators=80,random_state=23)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "mod=GridSearchCV(clf,param_grid={'n_estimators': [80,100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=80,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=23,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_estimators': [80, 100]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=23, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
